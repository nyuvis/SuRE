{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'user_defined'\n",
    "def output_test(cols, data, target_names, real_min, real_max, y_pred, y_gt):\n",
    "    filename = \"./output/\"+data_name+\"/test.json\"\n",
    "    directory = os.path.dirname(filename)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    to_output = {}\n",
    "    to_output['columns'] = cols\n",
    "    to_output['data'] = data\n",
    "    to_output['target_names'] = target_names\n",
    "    to_output['real_min'] = real_min\n",
    "    to_output['real_max'] = real_max\n",
    "    to_output['y_pred'] = y_pred\n",
    "    to_output['y_gt'] = y_gt\n",
    "    with open(filename, 'w') as output:\n",
    "        output.write(json.dumps(to_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "You can change the code below to read your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.368111</td>\n",
       "      <td>-0.766453</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.855474</td>\n",
       "      <td>-0.245013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.527025</td>\n",
       "      <td>0.626383</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.616431</td>\n",
       "      <td>-0.475369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016539</td>\n",
       "      <td>-0.975422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2   x3   x4   x5  y\n",
       "0  0.368111 -0.766453 -1.0  1.0 -1.0  0\n",
       "1  0.855474 -0.245013  1.0  1.0 -1.0  0\n",
       "2 -0.527025  0.626383 -1.0  1.0  1.0  0\n",
       "3  0.616431 -0.475369  1.0 -1.0  1.0  0\n",
       "4  0.016539 -0.975422  1.0  1.0 -1.0  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filepath_or_buffer=\"./input/synthetic_data.csv\", header=0, index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "'''prepare data'''\n",
    "X = df.drop(columns=['y']).values\n",
    "y = df['y'].values\n",
    "y = y.reshape(len(y))\n",
    "\n",
    "train, test, train_labels, test_labels = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "train_df = pd.DataFrame(train, columns=df.columns[:-1].values)\n",
    "test_df = pd.DataFrame(test, columns=df.columns[:-1].values)\n",
    "\n",
    "'''train the model'''\n",
    "clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "clf.fit(train, train_labels)\n",
    "\n",
    "'''report accuracy'''\n",
    "print(clf.score(test,test_labels ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''name the target classes'''\n",
    "target_names = [\"False\", \"True\"]\n",
    "min_val = np.min(X, axis=0)\n",
    "max_val = np.max(X, axis=0)\n",
    "\n",
    "y_pred = clf.predict(train)\n",
    "output_data(df.columns[:-1].values.tolist(), train.tolist(), target_names, \n",
    "            min_val.tolist(), max_val.tolist(),\n",
    "            y_pred.tolist(), train_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list = []\n",
    "\n",
    "for attr_idx in range(len(to_keep)):\n",
    "    hist = np.histogram(X[:, attr_idx], bins=10, range=(real_min[attr_idx], real_max[attr_idx]))\n",
    "    dist_list.append({\n",
    "        'hist': hist[0].tolist(),\n",
    "        'bin_edges': hist[1].tolist(),\n",
    "    })\n",
    "    \n",
    "with open('./output/'+ data_name + '/histogram.json', 'w') as output:\n",
    "    output.write(json.dumps({'histogram': dist_list}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prob(data):\n",
    "#     return np.array(list(zip(1-clf.predict(data),clf.predict(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851782363977486\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.821875"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test,test_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_svm = clf.predict(train)\n",
    "y_test_svm = clf.predict(test)\n",
    "y_svm_ = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' transform numerical values to categorical ones: low, medium, high '''\n",
    "real_3_1 = np.percentile(X, q=33, axis=0)\n",
    "real_3_2 = np.percentile(X, q=67, axis=0)\n",
    "\n",
    "def transform_func(col_idx, ele):\n",
    "    if (ele < real_3_1[col_idx]):\n",
    "        return 0\n",
    "    elif (ele < real_3_2[col_idx]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "cate_X = []\n",
    "for col_idx in range(X.shape[1]):\n",
    "     cate_X.append([transform_func(col_idx, ele) for ele in X[:, col_idx]])\n",
    "        \n",
    "cate_X = np.transpose(np.array(cate_X))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_percentile = {\n",
    "    'num_threshold': 2,\n",
    "    'percentile': [.33, .67],\n",
    "    'percentile_table': [real_3_1.tolist(), real_3_2.tolist()]\n",
    "}\n",
    "output_test(list(to_keep), X.tolist(), target_names, real_min.tolist(), real_max.tolist(), \n",
    "            real_percentile, y_pred.tolist(), y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_label = np.zeros(shape=y_svm.shape)\n",
    "# new_label[wrong_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_threshold = {\n",
    "    'support': 20,\n",
    "    'fidelity': 0.9,\n",
    "    'num_feat': 5,\n",
    "    'depth': 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7823639774859287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=1234, min_samples_leaf=filter_threshold['support'])\n",
    "rfc.fit(cate_X, y_svm_)\n",
    "print(rfc.score(cate_X, y_svm_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' get tree info from the forest '''\n",
    "estimators = rfc.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tree_node_info' from '/Users/junyuan/Documents/_/python/rule_vis/tree_node_info.py'>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tree_node_info\n",
    "importlib.reload(tree_node_info)\n",
    "\n",
    "# tree_node_obj = tree_node_info.tree_node_info()\n",
    "# tree_node_obj.initialize(estimators[0], cate_X, y, y_svm_, to_keep, filter_threshold)\n",
    "# tree_node_obj.node_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_list = []    \n",
    "tree_node_obj = tree_node_info.tree_node_info()\n",
    "\n",
    "for estimator in estimators:\n",
    "    tree_node_obj.initialize(estimator, cate_X, y, y_svm_, to_keep, filter_threshold)\n",
    "    tree_list.append(tree_node_obj.node_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tree_node_info.forest at 0x11c237350>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''construct a tree'''\n",
    "forest_obj = tree_node_info.forest()\n",
    "forest_obj.initialize(tree_list, cate_X, y, y_svm_, to_keep).construct_tree()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_tree = forest_obj.get_vis_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forest_obj.leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' output_tree is for outputing the tree data in a hierarchical form '''\n",
    "def output_tree(tree):\n",
    "    filename = \"./output/\"+data_name+\"/tree.json\"\n",
    "    directory = os.path.dirname(filename)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(filename, 'w') as output:\n",
    "        output.write(json.dumps({\n",
    "            \"tree\": tree,\n",
    "        }))\n",
    "\n",
    "def output_node_info(node_info_arr):\n",
    "    filename = \"./output/\"+data_name+\"/node_info.json\"\n",
    "    directory = os.path.dirname(filename)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(filename, 'w') as output:\n",
    "        output.write(json.dumps(\n",
    "            {\"node_info_arr\": node_info_arr,\n",
    "             \"max_depth\": estimator.tree_.max_depth,\n",
    "            }))\n",
    "        \n",
    "output_node_info(forest_obj.tree_node_dict)\n",
    "output_tree(vis_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_range = np.zeros(shape=(len(to_keep), 3, 2))\n",
    "\n",
    "for idx in range(len(to_keep)):\n",
    "    rep_range[idx][0] = np.array([real_min[idx], real_3_1[idx]])\n",
    "    rep_range[idx][1] = np.array([real_3_1[idx], real_3_2[idx]])\n",
    "    rep_range[idx][2] = np.array([real_3_2[idx], real_max[idx]])\n",
    "    \n",
    "    \n",
    "def translate_rule(feat_range, feat_idx):\n",
    "    # find the integers that fit\n",
    "    ranges = []\n",
    "    for i in range(3):\n",
    "        if (i >= feat_range[0] and i <= feat_range[1]):\n",
    "            ranges.append(i)\n",
    "    \n",
    "    # translate the integer into rule condition\n",
    "    if (ranges[0] == 0):\n",
    "        # (min, threshold]\n",
    "        cond = {\n",
    "            'feature': feat_idx,\n",
    "            'sign': '<=',\n",
    "            'threshold': rep_range[feat_idx][ranges[-1]][1]\n",
    "        }\n",
    "    elif (ranges[-1] == 2):\n",
    "        # (threshold, max]\n",
    "        cond = {\n",
    "            'feature': feat_idx,\n",
    "            'sign': '>',\n",
    "            'threshold': rep_range[feat_idx][ranges[0]][0]\n",
    "        }\n",
    "    else:\n",
    "        # (threshold0, threshold1]\n",
    "        cond = {\n",
    "            'feature': feat_idx,\n",
    "            'sign': 'range',\n",
    "            'threshold0': rep_range[feat_idx][ranges[0]][0],\n",
    "            'threshold1': rep_range[feat_idx][ranges[-1]][1]\n",
    "        }\n",
    "    return cond\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== leave node 6 ==========\n",
      "========== leave node 7 ==========\n",
      "========== leave node 11 ==========\n",
      "========== leave node 13 ==========\n",
      "========== leave node 19 ==========\n",
      "========== leave node 20 ==========\n",
      "========== leave node 23 ==========\n",
      "========== leave node 28 ==========\n",
      "========== leave node 33 ==========\n",
      "========== leave node 35 ==========\n",
      "========== leave node 36 ==========\n",
      "========== leave node 40 ==========\n",
      "========== leave node 47 ==========\n",
      "========== leave node 48 ==========\n",
      "========== leave node 50 ==========\n",
      "========== leave node 54 ==========\n",
      "========== leave node 61 ==========\n",
      "========== leave node 64 ==========\n",
      "========== leave node 69 ==========\n",
      "========== leave node 75 ==========\n",
      "========== leave node 76 ==========\n",
      "========== leave node 81 ==========\n",
      "========== leave node 84 ==========\n",
      "========== leave node 88 ==========\n",
      "========== leave node 90 ==========\n",
      "========== leave node 91 ==========\n",
      "========== leave node 94 ==========\n",
      "========== leave node 97 ==========\n",
      "========== leave node 98 ==========\n",
      "========== leave node 103 ==========\n",
      "========== leave node 108 ==========\n",
      "========== leave node 109 ==========\n",
      "========== leave node 113 ==========\n",
      "========== leave node 120 ==========\n",
      "========== leave node 125 ==========\n"
     ]
    }
   ],
   "source": [
    "'''trace back from leaves'''\n",
    "tree_features = estimator.tree_.feature\n",
    "node_threshold = estimator.tree_.threshold\n",
    "rule_lists = []\n",
    "\n",
    "for i in range(len(forest_obj.leaves)):\n",
    "    node_id = forest_obj.leaves[i]\n",
    "    print(\"=\"*10, \"leave node %d\"%(node_id), \"=\"*10)\n",
    "    feature_range = np.zeros(shape=(len(to_keep), 2), dtype=np.float128)\n",
    "    feature_range[:, 0] = 0\n",
    "    feature_range[:, 1] = 2\n",
    "\n",
    "    while node_id >= 0:\n",
    "        p_id = forest_obj.tree_node_dict[node_id]['parent']\n",
    "        sign = forest_obj.tree_node_dict[node_id]['sign']\n",
    "        if (p_id >= 0):\n",
    "            f_idx = forest_obj.tree_node_dict[p_id]['feature']\n",
    "            thrshd = forest_obj.tree_node_dict[p_id]['threshold']\n",
    "            if (sign == '<='):\n",
    "                # (min, thrshd)\n",
    "                if (feature_range[f_idx][1] > thrshd):\n",
    "                    feature_range[f_idx][1] = thrshd\n",
    "            else:\n",
    "                # (thrshd, max)\n",
    "                if (feature_range[f_idx][0] < thrshd):\n",
    "                    feature_range[f_idx][0] = thrshd\n",
    "        node_id = p_id\n",
    "#         print(\"rules:\")\n",
    "    rules = []\n",
    "    for j in range(len(feature_range)):\n",
    "        rule_str = to_keep[j]\n",
    "        # summarize the condition\n",
    "        if (feature_range[j][0]!=0 or feature_range[j][1]!=2):\n",
    "            new_cond = translate_rule(feature_range[j], j)\n",
    "            rules.append(new_cond)\n",
    "    rule_lists.append({\n",
    "        \"label\": int(np.argmax(forest_obj.tree_node_dict[forest_obj.leaves[i]]['value'])),\n",
    "        \"node_id\": int(forest_obj.leaves[i]),\n",
    "        \"rules\": rules,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "{'rule_lists': [{'label': 0, 'node_id': 125, 'rules': [{'feature': 0, 'sign': '>', 'threshold': 8.8}, {'feature': 1, 'sign': '<=', 'threshold': 0.42999999999999994}, {'feature': 2, 'sign': '>', 'threshold': 0.37}, {'feature': 3, 'sign': '<=', 'threshold': 2.0}, {'feature': 4, 'sign': '<=', 'threshold': 0.07400000000000001}]}, {'label': 0, 'node_id': 120, 'rules': [{'feature': 1, 'sign': 'range', 'threshold0': 0.42999999999999994, 'threshold1': 0.6}, {'feature': 4, 'sign': '<=', 'threshold': 0.07400000000000001}, {'feature': 5, 'sign': '>', 'threshold': 10.0}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 113, 'rules': [{'feature': 2, 'sign': '>', 'threshold': 0.15}, {'feature': 4, 'sign': '<=', 'threshold': 0.07400000000000001}, {'feature': 5, 'sign': '<=', 'threshold': 10.0}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 109, 'rules': [{'feature': 4, 'sign': '<=', 'threshold': 0.07400000000000001}, {'feature': 5, 'sign': '>', 'threshold': 10.0}, {'feature': 6, 'sign': '<=', 'threshold': 26.0}]}, {'label': 0, 'node_id': 108, 'rules': [{'feature': 4, 'sign': '<=', 'threshold': 0.07400000000000001}, {'feature': 5, 'sign': '>', 'threshold': 10.0}, {'feature': 6, 'sign': 'range', 'threshold0': 26.0, 'threshold1': 52.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 103, 'rules': [{'feature': 2, 'sign': '<=', 'threshold': 0.37}, {'feature': 3, 'sign': 'range', 'threshold0': 2.0, 'threshold1': 2.4}, {'feature': 5, 'sign': '>', 'threshold': 18.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 98, 'rules': [{'feature': 1, 'sign': '<=', 'threshold': 0.42999999999999994}, {'feature': 2, 'sign': '>', 'threshold': 0.37}, {'feature': 5, 'sign': '<=', 'threshold': 10.0}, {'feature': 8, 'sign': '<=', 'threshold': 3.37}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 97, 'rules': [{'feature': 1, 'sign': '<=', 'threshold': 0.42999999999999994}, {'feature': 2, 'sign': '>', 'threshold': 0.37}, {'feature': 5, 'sign': 'range', 'threshold0': 10.0, 'threshold1': 18.0}, {'feature': 8, 'sign': '<=', 'threshold': 3.37}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 94, 'rules': [{'feature': 1, 'sign': '<=', 'threshold': 0.42999999999999994}, {'feature': 2, 'sign': '>', 'threshold': 0.37}, {'feature': 8, 'sign': '>', 'threshold': 3.37}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 91, 'rules': [{'feature': 1, 'sign': '<=', 'threshold': 0.42999999999999994}, {'feature': 3, 'sign': '<=', 'threshold': 2.4}, {'feature': 6, 'sign': '<=', 'threshold': 26.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 90, 'rules': [{'feature': 1, 'sign': '<=', 'threshold': 0.42999999999999994}, {'feature': 3, 'sign': '<=', 'threshold': 2.4}, {'feature': 6, 'sign': '>', 'threshold': 26.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 88, 'rules': [{'feature': 1, 'sign': '<=', 'threshold': 0.42999999999999994}, {'feature': 3, 'sign': '>', 'threshold': 2.4}, {'feature': 5, 'sign': '<=', 'threshold': 18.0}, {'feature': 8, 'sign': '<=', 'threshold': 3.25}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 84, 'rules': [{'feature': 0, 'sign': '>', 'threshold': 8.8}, {'feature': 1, 'sign': 'range', 'threshold0': 0.42999999999999994, 'threshold1': 0.6}, {'feature': 6, 'sign': '<=', 'threshold': 26.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 81, 'rules': [{'feature': 1, 'sign': '>', 'threshold': 0.42999999999999994}, {'feature': 3, 'sign': '<=', 'threshold': 2.4}, {'feature': 6, 'sign': 'range', 'threshold0': 26.0, 'threshold1': 52.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 76, 'rules': [{'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 7, 'sign': '<=', 'threshold': 0.996}, {'feature': 8, 'sign': '<=', 'threshold': 3.25}, {'feature': 9, 'sign': '>', 'threshold': 0.68}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 75, 'rules': [{'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 7, 'sign': '<=', 'threshold': 0.996}, {'feature': 8, 'sign': '>', 'threshold': 3.25}, {'feature': 9, 'sign': '>', 'threshold': 0.68}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 69, 'rules': [{'feature': 0, 'sign': '>', 'threshold': 8.8}, {'feature': 1, 'sign': '<=', 'threshold': 0.42999999999999994}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 9, 'sign': '<=', 'threshold': 0.68}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 64, 'rules': [{'feature': 2, 'sign': '>', 'threshold': 0.37}, {'feature': 3, 'sign': '<=', 'threshold': 2.4}, {'feature': 4, 'sign': '<=', 'threshold': 0.07400000000000001}, {'feature': 9, 'sign': '>', 'threshold': 0.68}, {'feature': 10, 'sign': '>', 'threshold': 9.7}]}, {'label': 0, 'node_id': 61, 'rules': [{'feature': 0, 'sign': '<=', 'threshold': 8.8}, {'feature': 3, 'sign': '>', 'threshold': 2.4}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 9, 'sign': '>', 'threshold': 0.68}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 54, 'rules': [{'feature': 5, 'sign': '>', 'threshold': 10.0}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 8, 'sign': '<=', 'threshold': 3.37}, {'feature': 9, 'sign': '>', 'threshold': 0.68}, {'feature': 10, 'sign': 'range', 'threshold0': 9.7, 'threshold1': 10.8}]}, {'label': 0, 'node_id': 50, 'rules': [{'feature': 0, 'sign': '<=', 'threshold': 8.8}, {'feature': 1, 'sign': '<=', 'threshold': 0.42999999999999994}, {'feature': 2, 'sign': '<=', 'threshold': 0.37}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 48, 'rules': [{'feature': 0, 'sign': '>', 'threshold': 8.8}, {'feature': 1, 'sign': '<=', 'threshold': 0.42999999999999994}, {'feature': 4, 'sign': '<=', 'threshold': 0.086}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 47, 'rules': [{'feature': 0, 'sign': '>', 'threshold': 8.8}, {'feature': 1, 'sign': '<=', 'threshold': 0.42999999999999994}, {'feature': 4, 'sign': '>', 'threshold': 0.086}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 40, 'rules': [{'feature': 2, 'sign': '<=', 'threshold': 0.37}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 8, 'sign': '<=', 'threshold': 3.37}, {'feature': 9, 'sign': '>', 'threshold': 0.68}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 36, 'rules': [{'feature': 2, 'sign': '>', 'threshold': 0.37}, {'feature': 4, 'sign': '<=', 'threshold': 0.07400000000000001}, {'feature': 5, 'sign': '<=', 'threshold': 10.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 35, 'rules': [{'feature': 2, 'sign': '>', 'threshold': 0.37}, {'feature': 4, 'sign': '<=', 'threshold': 0.07400000000000001}, {'feature': 5, 'sign': '>', 'threshold': 10.0}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 33, 'rules': [{'feature': 2, 'sign': '>', 'threshold': 0.37}, {'feature': 4, 'sign': '>', 'threshold': 0.07400000000000001}, {'feature': 8, 'sign': '>', 'threshold': 3.25}, {'feature': 9, 'sign': '>', 'threshold': 0.68}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 28, 'rules': [{'feature': 2, 'sign': '<=', 'threshold': 0.37}, {'feature': 4, 'sign': '<=', 'threshold': 0.07400000000000001}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 8, 'sign': '<=', 'threshold': 3.37}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 23, 'rules': [{'feature': 2, 'sign': '>', 'threshold': 0.37}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 8, 'sign': '<=', 'threshold': 3.25}, {'feature': 9, 'sign': '<=', 'threshold': 0.68}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 20, 'rules': [{'feature': 2, 'sign': '>', 'threshold': 0.37}, {'feature': 3, 'sign': '<=', 'threshold': 2.4}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 9, 'sign': '>', 'threshold': 0.68}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 19, 'rules': [{'feature': 2, 'sign': '>', 'threshold': 0.37}, {'feature': 3, 'sign': '>', 'threshold': 2.4}, {'feature': 6, 'sign': '<=', 'threshold': 52.0}, {'feature': 9, 'sign': '>', 'threshold': 0.68}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 13, 'rules': [{'feature': 3, 'sign': '<=', 'threshold': 2.4}, {'feature': 6, 'sign': '<=', 'threshold': 26.0}, {'feature': 8, 'sign': '<=', 'threshold': 3.25}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 11, 'rules': [{'feature': 1, 'sign': '<=', 'threshold': 0.42999999999999994}, {'feature': 3, 'sign': '<=', 'threshold': 2.4}, {'feature': 8, 'sign': 'range', 'threshold0': 3.25, 'threshold1': 3.37}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 7, 'rules': [{'feature': 5, 'sign': '>', 'threshold': 10.0}, {'feature': 6, 'sign': '<=', 'threshold': 26.0}, {'feature': 8, 'sign': '>', 'threshold': 3.37}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}, {'label': 0, 'node_id': 6, 'rules': [{'feature': 5, 'sign': '>', 'threshold': 10.0}, {'feature': 6, 'sign': '>', 'threshold': 26.0}, {'feature': 8, 'sign': '>', 'threshold': 3.37}, {'feature': 9, 'sign': '>', 'threshold': 0.68}, {'feature': 10, 'sign': '>', 'threshold': 10.8}]}], 'target_names': ['bad', 'good']}\n"
     ]
    }
   ],
   "source": [
    "def output_rule_list(rule_lists, target_names):\n",
    "    filename = \"./output/\"+data_name+\"/list.json\"\n",
    "    directory = os.path.dirname(filename)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    to_write = {\"rule_lists\": rule_lists, \"target_names\": target_names}\n",
    "    print(to_write)\n",
    "    with open(filename, 'w') as output:\n",
    "        output.write(json.dumps(to_write))\n",
    "        \n",
    "\n",
    "rule_lists.reverse()\n",
    "print(\"=\"*30)\n",
    "# print(rule_lists)\n",
    "output_rule_list(rule_lists, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tree_node_info\n",
    "# importlib.reload(tree_node_info)\n",
    "\n",
    "rs = tree_node_info.forest_rules()\n",
    "\n",
    "rs.initialize(df, rule_lists, real_min, real_max)\n",
    "ts = rs.find_the_min_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "leng = len(ts)\n",
    "fidel_list = []\n",
    "for rid in ts:\n",
    "    node_id = rule_lists[rid]['node_id']\n",
    "    fidel_list.append(forest_obj.tree_node_dict[node_id]['fidelity'])\n",
    "print(leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9204545454545454,\n",
       " 0.9186046511627907,\n",
       " 0.9342105263157895,\n",
       " 0.9302325581395349,\n",
       " 0.9178082191780822,\n",
       " 0.9705882352941176,\n",
       " 0.9180327868852459,\n",
       " 1.0,\n",
       " 0.9032258064516129,\n",
       " 0.9206349206349206,\n",
       " 0.9482758620689655,\n",
       " 0.9761904761904762,\n",
       " 0.9069767441860465,\n",
       " 0.9423076923076923,\n",
       " 0.9666666666666667,\n",
       " 1.0,\n",
       " 0.9074074074074074,\n",
       " 0.975609756097561,\n",
       " 0.9767441860465116,\n",
       " 0.9382716049382716,\n",
       " 0.9705882352941176,\n",
       " 0.9722222222222222,\n",
       " 0.9259259259259259,\n",
       " 0.9722222222222222]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fidel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' scaling '"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' scaling '''\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' projection '"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' projection '''\n",
    "# from sklearn.decomposition import PCA\n",
    "# import altair as alt\n",
    "\n",
    "# result_pca = PCA(n_components=2).fit_transform(scaled)\n",
    "# pca_df = pd.DataFrame(data=result_pca, columns=['x','y'])\n",
    "\n",
    "# alt.Chart(pca_df).mark_point().encode(\n",
    "#     x='x:Q',\n",
    "#     y='y:Q',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def output_projection(coordinate):\n",
    "#     filename = \"./output/\"+data_name+\"/projection.json\"\n",
    "#     directory = os.path.dirname(filename)\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "#     with open(filename, 'w') as output:\n",
    "#         output.write(json.dumps(\n",
    "#             {\"projection\": coordinate,\n",
    "#             }))\n",
    "# output_projection(result_pca.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
